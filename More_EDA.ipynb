{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa5cbbe0-5e8b-4d7b-b7b8-afa1f6c66a4e",
   "metadata": {},
   "source": [
    "So far, we have:\n",
    "\n",
    "Created a DataFrame\n",
    "Viewed the first and last rows using the head and tail methods\n",
    "Printed the column names\n",
    "Checked for null values\n",
    "Next, we'll dive deeper into our data to gain more insights. We'll explore the data types of each column and perform some descriptive analysis on the dataset.\n",
    "\n",
    "We're fortunate that our data is clean, meaning it doesn't contain any errors or inconsistencies. However, this isn't always the case. The steps we're taking now help us understand our dataset and identify potential issues early on.\n",
    "\n",
    "Understanding the data types of columns in a DataFrame is crucial because it influences how you analyze and manipulate the data. Different data types (e.g., integers, floats, strings, dates) allow for different operations and analyses. For example:\n",
    "\n",
    "Numerical columns support mathematical operations and statistical analysis.\n",
    "Categorical columns are useful for grouping and aggregation.\n",
    "Date/Time columns enable time-based filtering and analysis.\n",
    "\n",
    "How to Check Data Types in a DataFrame\n",
    "In pandas, you can easily check the data types of each column using the .dtypes attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1806bf-75dc-42a3-95ca-0ff138f07535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name        object\n",
      "Age          int64\n",
      "JoinDate    object\n",
      "IsMember      bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 22],\n",
    "    'JoinDate': ['2023-01-01', '2022-06-15', '2023-03-20'],\n",
    "    'IsMember': [True, False, True]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc526ad-8252-4cc4-94a3-3669bb7ed88b",
   "metadata": {},
   "source": [
    "What This Tells Us:\n",
    "\n",
    "Name is an object, typically indicating text data.\n",
    "Age is an int64, meaning it's a whole number and suitable for numerical operations.\n",
    "JoinDate is also an object, but since it's a date, we might need to convert it to a datetime type for date-based analysis.\n",
    "IsMember is a bool, useful for filtering and logical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83047513-c2a6-48b7-ac72-7756c7e2c182",
   "metadata": {},
   "source": [
    "Converting Data Types if Needed:\n",
    "\n",
    "If needed, you can convert data types using methods like pd.to_datetime() for dates or .astype() for other types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d44db69-c616-4213-80ee-5dfe2a9e8ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                object\n",
      "Age                  int64\n",
      "JoinDate    datetime64[ns]\n",
      "IsMember              bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'JoinDate' to datetime\n",
    "df['JoinDate'] = pd.to_datetime(df['JoinDate'])\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00d5f2-c069-4b26-8bd9-76b6c68fd98e",
   "metadata": {},
   "source": [
    "By ensuring the correct data types, you'll avoid errors and gain more powerful tools for data analysis.\n",
    "\n",
    "In the example above, we converted the data type of a single column. With pandas, you can target one column at a time by specifying its name within square brackets. This approach allows you to access or modify specific columns directly.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22110150-8573-4ce7-9af3-c5125ea900db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice', 'Bob', 'Charlie']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_frame['column_name_here']\n",
    "data['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339837b-6254-494b-bb4b-086c891a0f0c",
   "metadata": {},
   "source": [
    "Bringing it all together week 1\n",
    "\n",
    "When we start a new data project, one of the first things we do is read in the data and take a good look at it. This isn't just busywork—it's our chance to get the lay of the land before we dive into analysis.\n",
    "\n",
    "We kick things off by checking out the first and last few rows with head() and tail(). This gives us a quick snapshot of the data's structure and helps us catch anything weird right away, like unexpected values or formatting issues.\n",
    "\n",
    "Next, we hunt for nulls. Why? Because nothing derails a good analysis like missing data. If half a column is blank, we need to know so we can decide whether to fill those gaps, drop them, or handle them in some other way.\n",
    "\n",
    "We also check the shape of the DataFrame (.shape) to see how many rows and columns we’re dealing with. This is especially important when merging or transforming data—if our row count suddenly doubles, something probably went wrong.\n",
    "\n",
    "Finally, we look at descriptive stats (.describe()). This gives us a quick read on our numerical data—things like means, medians, min/max values, and percentiles. It helps us spot outliers and understand the data's spread, which can guide our next steps.\n",
    "\n",
    "This kind of exploratory data analysis (EDA) might feel like a routine, but it’s one of the best habits to build. It sets the stage for solid, reliable analysis and helps us avoid surprises down the road. Plus, as we get into more complex projects, these steps become even more crucial, think of them as our pre-flight checklist before taking off into deeper analytics or machine learning.\n",
    "\n",
    "Want to make your future self happy? Make EDA your new best friend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ce22e-34bf-47c2-9983-6a96527b5ed5",
   "metadata": {},
   "source": [
    "Understanding Null and Missing Values in pandas\n",
    "When working with data in pandas, you'll often encounter null or missing values. These represent the absence of data in a DataFrame or Series. Missing values can occur for various reasons, such as incomplete data collection, errors during data entry, or merging datasets with inconsistent records. In pandas, missing values are typically represented as NaN (Not a Number) for numeric data or None for object data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9dca9a-0bd9-41b3-ad6d-7ee21d4b64fa",
   "metadata": {},
   "source": [
    "Example of Missing Values\n",
    "Consider the following gradebook data with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de4cf1a-436f-45c6-97ed-430a5808338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Math  Science  English\n",
      "0    Alice  85.0     90.0      NaN\n",
      "1      Bob   NaN     88.0     80.0\n",
      "2  Charlie  78.0      NaN     87.0\n",
      "3    David  92.0     95.0     85.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Student\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Math\": [85, None, 78, 92],\n",
    "    \"Science\": [90, 88, None, 95],\n",
    "    \"English\": [None, 80, 87, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2058d-c5b2-4561-af55-1317fd2bfa31",
   "metadata": {},
   "source": [
    "In this example, some values are missing, represented by NaN.\n",
    "\n",
    "Handling Missing Values\n",
    "\n",
    "1. Removing Missing Values\n",
    "a. dropna() Method:\n",
    "\n",
    "How: Removes rows (or columns) containing missing values.\n",
    "When to Use: When missing values represent a small, insignificant portion of the dataset or when those records are not essential for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b2dfcc-a553-4eb9-a67e-d72f39ad769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student  Math  Science  English\n",
      "3   David  92.0     95.0     85.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Student\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Math\": [85, None, 78, 92],\n",
    "    \"Science\": [90, 88, None, 95],\n",
    "    \"English\": [None, 80, 87, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1eec12-8297-411b-9816-06b4a3506d24",
   "metadata": {},
   "source": [
    "Pros: Ensures only complete data is used, which can improve the reliability of analysis.\n",
    "Cons: Potentially reduces the dataset size significantly, leading to biased results if many rows are removed.\n",
    "\n",
    "2. Filling Missing Values\n",
    "a. fillna() Method:\n",
    "\n",
    "How: Replaces NaN values with a specified value (e.g., a fixed number, the mean of the column, or forward/backward filling).\n",
    "When to Use: When removing rows is not ideal, and estimates or placeholders can be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18e0efa-fe6e-455d-972e-74b5f5671eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Math  Science  English\n",
      "0    Alice  85.0     90.0      0.0\n",
      "1      Bob   0.0     88.0     80.0\n",
      "2  Charlie  78.0      0.0     87.0\n",
      "3    David  92.0     95.0     85.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Student\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Math\": [85, None, 78, 92],\n",
    "    \"Science\": [90, 88, None, 95],\n",
    "    \"English\": [None, 80, 87, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_filled = df.fillna(0)  # Fill with 0\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41970346-7103-4b32-8aec-de9c7f565c2f",
   "metadata": {},
   "source": [
    "Alternative Filling Strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e48ed-43c6-4d5c-8a2a-6d8d54812075",
   "metadata": {},
   "source": [
    "Pros: Preserves the size of the dataset. Useful when the missing data is not entirely random or when approximate values can be used.\n",
    "Cons: Can introduce bias if the filled values do not accurately reflect the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af2a70d-5ae5-4ed2-a1ad-44f88d595025",
   "metadata": {},
   "source": [
    "When to Remove vs. When to Fill\n",
    "\n",
    "✅ Remove Missing Values: When the dataset is large, and the missing data is minimal or irrelevant to your analysis. This is ideal for ensuring only high-quality data is used.\n",
    "✅ Fill Missing Values: When preserving the dataset size is crucial, and the missing values can be reasonably estimated. This approach is helpful for maintaining trends or sequences, such as in time series data.\n",
    "\n",
    "By carefully considering the context of your data and analysis goals, you can choose the appropriate method to handle missing values effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc41ea56-c355-409b-bdf9-0ca8dcb60f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Math  Science  English\n",
      "0    Alice  85.0     90.0     84.0\n",
      "1      Bob  85.0     88.0     80.0\n",
      "2  Charlie  78.0     91.0     87.0\n",
      "3    David  92.0     95.0     85.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Student\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Math\": [85, None, 78, 92],\n",
    "    \"Science\": [90, 88, None, 95],\n",
    "    \"English\": [None, 80, 87, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# df_filled = df.fillna(0)  # Fill with 0\n",
    "\n",
    "# The below line does not run because my DataFrame has non-numeric columns like strings (e.g., names, categories, etc.)\n",
    "# df_mean_filled = df.fillna(df.mean())  # Fill with column mean\n",
    "\n",
    "# Fill NaN in numeric columns with their mean\n",
    "df_mean_filled = df.fillna(df.select_dtypes(include='number').mean())\n",
    "\n",
    "#️⃣ This line:\n",
    "# ❇️ Selects only numeric columns using select_dtypes(include='number').\n",
    "# ❇️ Calculates the mean only for numeric columns.\n",
    "# ❇️ Fills NaN values in those columns with their respective means.\n",
    "\n",
    "# print(df_filled)\n",
    "print(df_mean_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca48a6dc-8392-4a86-a0db-d5061f6f3fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Math  Science  English\n",
      "0    Alice  85.0     90.0      NaN\n",
      "1      Bob  85.0     88.0     80.0\n",
      "2  Charlie  78.0     88.0     87.0\n",
      "3    David  92.0     95.0     85.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asaad\\AppData\\Local\\Temp\\ipykernel_21576\\1619610541.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_forward_filled = df.fillna(method='ffill')  # Forward fill\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Student\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Math\": [85, None, 78, 92],\n",
    "    \"Science\": [90, 88, None, 95],\n",
    "    \"English\": [None, 80, 87, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# df_filled = df.fillna(0)  # Fill with 0\n",
    "df_forward_filled = df.fillna(method='ffill')  # Forward fill\n",
    "# print(df_filled)\n",
    "print(df_forward_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0249bd-d7dd-45fe-9576-5290a000baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Math  Science  English\n",
      "0    Alice  85.0     90.0      NaN\n",
      "1      Bob  85.0     88.0     80.0\n",
      "2  Charlie  78.0     88.0     87.0\n",
      "3    David  92.0     95.0     85.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asaad\\AppData\\Local\\Temp\\ipykernel_21576\\2386707875.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_backward_filled = df.fillna(method='bfill')  # Backward fill\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Student\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Math\": [85, None, 78, 92],\n",
    "    \"Science\": [90, 88, None, 95],\n",
    "    \"English\": [None, 80, 87, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# df_filled = df.fillna(0)  # Fill with 0\n",
    "df_backward_filled = df.fillna(method='bfill')  # Backward fill\n",
    "# print(df_filled)\n",
    "print(df_forward_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6b993-97b4-4c65-8216-0cd4159d2ebd",
   "metadata": {},
   "source": [
    "Our client, the Kentucky School Board, recently digitized records from the 1950s. Unfortunately, a coffee spill damaged some of the original documents, resulting in lost data. To restore the missing information, we would like to fill the gaps with the class averages for each subject. The relevant class data has been extracted from the database. Please write a script to repair the data accordingly.\n",
    "\n",
    "Sales Team Dashboard Issue\n",
    "\n",
    "Instructor Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a89850b5-df28-403d-83c6-3b6bb954620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee  Sales  Marketing          IT\n",
      "0   Evelyn  250.0      190.0  150.000000\n",
      "1    Frank  275.0      180.0  160.000000\n",
      "2    Grace  300.0      200.0  161.666667\n",
      "3    Henry  275.0      190.0  175.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Employee\": [\"Evelyn\", \"Frank\", \"Grace\", \"Henry\"],\n",
    "    \"Sales\": [250, None, 300, 275],\n",
    "    \"Marketing\": [None, 180, 200, 190],\n",
    "    \"IT\": [150, 160, None, 175]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# your code here \n",
    "\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce2ea8-af7d-45ca-b881-c6e8e9eb7d82",
   "metadata": {},
   "source": [
    "Transpose in Python: In Python, transposing a DataFrame means swapping its rows and columns. This is achieved using the .T attribute of a pandas DataFrame. When transposed, the original rows become columns and vice versa. Transposing is particularly useful when you want to change the orientation of your data, making it easier to perform column-wise operations that might otherwise require row-wise calculations. For example, in the context of a gradebook or sales data, transposing can help align the data by subjects or products, enabling more straightforward aggregation and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a95b08-ba45-44c8-bb67-f1ce3b06b40f",
   "metadata": {},
   "source": [
    "Calculating Column Means: Once the DataFrame is transposed, calculating the mean of each column is simple with the .mean() method. The .mean() function computes the arithmetic mean of numerical values within each column, ignoring any NaN values by default. By chaining .round(), the mean values are rounded to the nearest whole number, which can enhance readability or suit specific use cases. These mean values can be stored as a Series, allowing them to be reused for filling missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa258cb-39bd-4666-a470-dc423d46b500",
   "metadata": {},
   "source": [
    "Filling Missing Values: Filling NaN values with column averages is a practical method in data cleaning, especially when missing data is sparse and you want to maintain the overall distribution of the dataset. This approach is particularly useful when the dataset is large enough that individual missing values are unlikely to skew results. Using the .fillna() method, missing values are replaced by their respective column averages, which helps to avoid introducing bias or losing valuable data by simply dropping rows or columns with missing values. This technique is often applied in scenarios such as gradebooks, sales data, and any situation where you need to preserve as much information as possible while preparing the data for analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a78e2fa-c84e-460a-8bc6-7e3ed9b51831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Means (Rounded):\n",
      " Apples       159.0\n",
      "Bananas      169.0\n",
      "Cherries     211.0\n",
      "Dates        129.0\n",
      "Eggplants    100.0\n",
      "dtype: float64\n",
      "\n",
      "Updated DataFrame:\n",
      "          Apples  Bananas  Cherries  Dates  Eggplants\n",
      "Store_1   150.0    169.0     200.0  120.0       90.0\n",
      "Store_2   159.0    180.0     210.0  129.0      100.0\n",
      "Store_3   170.0    160.0     211.0  130.0      100.0\n",
      "Store_4   160.0    170.0     220.0  140.0      110.0\n",
      "Store_5   155.0    169.0     215.0  125.0       95.0\n",
      "Store_6   159.0    165.0     211.0  129.0      105.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sales data for different products in various stores with some missing values\n",
    "sales_data = {\n",
    "    \"Store_1\": {\"Apples\": 150, \"Bananas\": None, \"Cherries\": 200, \"Dates\": 120, \"Eggplants\": 90},\n",
    "    \"Store_2\": {\"Apples\": None, \"Bananas\": 180, \"Cherries\": 210, \"Dates\": None, \"Eggplants\": 100},\n",
    "    \"Store_3\": {\"Apples\": 170, \"Bananas\": 160, \"Cherries\": None, \"Dates\": 130, \"Eggplants\": None},\n",
    "    \"Store_4\": {\"Apples\": 160, \"Bananas\": 170, \"Cherries\": 220, \"Dates\": 140, \"Eggplants\": 110},\n",
    "    \"Store_5\": {\"Apples\": 155, \"Bananas\": None, \"Cherries\": 215, \"Dates\": 125, \"Eggplants\": 95},\n",
    "    \"Store_6\": {\"Apples\": None, \"Bananas\": 165, \"Cherries\": None, \"Dates\": None, \"Eggplants\": 105},\n",
    "}\n",
    "\n",
    "# Convert to a DataFrame and transpose\n",
    "sales_df = pd.DataFrame(sales_data).T\n",
    "\n",
    "# Calculate column means (rounded)\n",
    "column_means = sales_df.mean().round()\n",
    "print(\"Column Means (Rounded):\\n\", column_means)\n",
    "\n",
    "# Fill NaN values with column averages\n",
    "sales_df = sales_df.fillna(column_means)\n",
    "\n",
    "print(\"\\nUpdated DataFrame:\\n\", sales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d75bcb-8d9a-49e7-aed5-e1223265e682",
   "metadata": {},
   "source": [
    "Kentucky School Board Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "901d0b93-e766-49c9-8cdf-fffbb037efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Means (Rounded):\n",
      " Student_1     86.0\n",
      "Student_2     80.0\n",
      "Student_3     83.0\n",
      "Student_4     91.0\n",
      "Student_5     76.0\n",
      "Student_6     88.0\n",
      "Student_7     82.0\n",
      "Student_8     94.0\n",
      "Student_9     86.0\n",
      "Student_10    84.0\n",
      "Student_11    75.0\n",
      "Student_12    90.0\n",
      "Student_13    84.0\n",
      "Student_14    89.0\n",
      "Student_15    82.0\n",
      "dtype: float64\n",
      "\n",
      "Updated DataFrame:\n",
      "          Student_1  Student_2  Student_3  Student_4  Student_5  Student_6  \\\n",
      "Math          85.0       74.0       83.0       92.0       67.0         88   \n",
      "Science       90.0       80.0       85.0       89.0       73.0         92   \n",
      "History       78.0       88.0       91.0       91.0       80.0         84   \n",
      "English       86.0       80.0       87.0       95.0       85.0         90   \n",
      "Art           92.0       76.0       70.0       88.0       76.0         86   \n",
      "\n",
      "         Student_7  Student_8  Student_9  Student_10  Student_11  Student_12  \\\n",
      "Math          76.0       95.0       86.0        81.0        69.0        90.0   \n",
      "Science       82.0       97.0       82.0        87.0        74.0        91.0   \n",
      "History       79.0       94.0       85.0        90.0        80.0        85.0   \n",
      "English       83.0       93.0       88.0        84.0        77.0        90.0   \n",
      "Art           91.0       89.0       90.0        78.0        75.0        93.0   \n",
      "\n",
      "         Student_13  Student_14  Student_15  \n",
      "Math           86.0        90.0        82.0  \n",
      "Science        84.0        85.0        80.0  \n",
      "History        88.0        92.0        75.0  \n",
      "English        82.0        88.0        85.0  \n",
      "Art            79.0        89.0        87.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gradebook = {\n",
    "    \"Student_1\": {\"Math\": 85, \"Science\": 90, \"History\": 78, \"English\": None, \"Art\": 92},\n",
    "    \"Student_2\": {\"Math\": 74, \"Science\": None, \"History\": 88, \"English\": 80, \"Art\": 76},\n",
    "    \"Student_3\": {\"Math\": None, \"Science\": 85, \"History\": 91, \"English\": 87, \"Art\": 70},\n",
    "    \"Student_4\": {\"Math\": 92, \"Science\": 89, \"History\": None, \"English\": 95, \"Art\": 88},\n",
    "    \"Student_5\": {\"Math\": 67, \"Science\": 73, \"History\": 80, \"English\": 85, \"Art\": None},\n",
    "    \"Student_6\": {\"Math\": 88, \"Science\": 92, \"History\": 84, \"English\": 90, \"Art\": 86},\n",
    "    \"Student_7\": {\"Math\": 76, \"Science\": None, \"History\": 79, \"English\": 83, \"Art\": 91},\n",
    "    \"Student_8\": {\"Math\": 95, \"Science\": 97, \"History\": None, \"English\": 93, \"Art\": 89},\n",
    "    \"Student_9\": {\"Math\": None, \"Science\": 82, \"History\": 85, \"English\": 88, \"Art\": 90},\n",
    "    \"Student_10\": {\"Math\": 81, \"Science\": 87, \"History\": 90, \"English\": None, \"Art\": 78},\n",
    "    \"Student_11\": {\"Math\": 69, \"Science\": 74, \"History\": 80, \"English\": 77, \"Art\": None},\n",
    "    \"Student_12\": {\"Math\": None, \"Science\": 91, \"History\": 85, \"English\": 90, \"Art\": 93},\n",
    "    \"Student_13\": {\"Math\": 86, \"Science\": None, \"History\": 88, \"English\": 82, \"Art\": 79},\n",
    "    \"Student_14\": {\"Math\": 90, \"Science\": 85, \"History\": 92, \"English\": 88, \"Art\": None},\n",
    "    \"Student_15\": {\"Math\": None, \"Science\": 80, \"History\": 75, \"English\": 85, \"Art\": 87},\n",
    "}\n",
    "\n",
    "gradebook_df = pd.DataFrame(gradebook)\n",
    "\n",
    "#transpose the data \n",
    "grades_df_t = pd.DataFrame(gradebook).T\n",
    "\n",
    "# Calculate the column means (rounded)\n",
    "column_means = gradebook_df.mean().round()\n",
    "print(\"Column Means (Rounded):\\n\", column_means)\n",
    "\n",
    "# Fill NaN values with column averages\n",
    "grades_df_t = gradebook_df.fillna(column_means)\n",
    "\n",
    "print(\"\\nUpdated DataFrame:\\n\", grades_df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a92fcf-3ad4-490f-8c4b-db864312090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Means (Rounded):\n",
      " Math       82.0\n",
      "Science    85.0\n",
      "History    84.0\n",
      "English    86.0\n",
      "Art        85.0\n",
      "dtype: float64\n",
      "\n",
      "Updated DataFrame:\n",
      "             Math  Science  History  English   Art\n",
      "Student_1   85.0     90.0     78.0     86.0  92.0\n",
      "Student_2   74.0     85.0     88.0     80.0  76.0\n",
      "Student_3   82.0     85.0     91.0     87.0  70.0\n",
      "Student_4   92.0     89.0     84.0     95.0  88.0\n",
      "Student_5   67.0     73.0     80.0     85.0  85.0\n",
      "Student_6   88.0     92.0     84.0     90.0  86.0\n",
      "Student_7   76.0     85.0     79.0     83.0  91.0\n",
      "Student_8   95.0     97.0     84.0     93.0  89.0\n",
      "Student_9   82.0     82.0     85.0     88.0  90.0\n",
      "Student_10  81.0     87.0     90.0     86.0  78.0\n",
      "Student_11  69.0     74.0     80.0     77.0  85.0\n",
      "Student_12  82.0     91.0     85.0     90.0  93.0\n",
      "Student_13  86.0     85.0     88.0     82.0  79.0\n",
      "Student_14  90.0     85.0     92.0     88.0  85.0\n",
      "Student_15  82.0     80.0     75.0     85.0  87.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gradebook = {\n",
    "    \"Student_1\": {\"Math\": 85, \"Science\": 90, \"History\": 78, \"English\": None, \"Art\": 92},\n",
    "    \"Student_2\": {\"Math\": 74, \"Science\": None, \"History\": 88, \"English\": 80, \"Art\": 76},\n",
    "    \"Student_3\": {\"Math\": None, \"Science\": 85, \"History\": 91, \"English\": 87, \"Art\": 70},\n",
    "    \"Student_4\": {\"Math\": 92, \"Science\": 89, \"History\": None, \"English\": 95, \"Art\": 88},\n",
    "    \"Student_5\": {\"Math\": 67, \"Science\": 73, \"History\": 80, \"English\": 85, \"Art\": None},\n",
    "    \"Student_6\": {\"Math\": 88, \"Science\": 92, \"History\": 84, \"English\": 90, \"Art\": 86},\n",
    "    \"Student_7\": {\"Math\": 76, \"Science\": None, \"History\": 79, \"English\": 83, \"Art\": 91},\n",
    "    \"Student_8\": {\"Math\": 95, \"Science\": 97, \"History\": None, \"English\": 93, \"Art\": 89},\n",
    "    \"Student_9\": {\"Math\": None, \"Science\": 82, \"History\": 85, \"English\": 88, \"Art\": 90},\n",
    "    \"Student_10\": {\"Math\": 81, \"Science\": 87, \"History\": 90, \"English\": None, \"Art\": 78},\n",
    "    \"Student_11\": {\"Math\": 69, \"Science\": 74, \"History\": 80, \"English\": 77, \"Art\": None},\n",
    "    \"Student_12\": {\"Math\": None, \"Science\": 91, \"History\": 85, \"English\": 90, \"Art\": 93},\n",
    "    \"Student_13\": {\"Math\": 86, \"Science\": None, \"History\": 88, \"English\": 82, \"Art\": 79},\n",
    "    \"Student_14\": {\"Math\": 90, \"Science\": 85, \"History\": 92, \"English\": 88, \"Art\": None},\n",
    "    \"Student_15\": {\"Math\": None, \"Science\": 80, \"History\": 75, \"English\": 85, \"Art\": 87},\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "gradebook_df = pd.DataFrame(gradebook)\n",
    "\n",
    "# Transpose the DataFrame (students as rows)\n",
    "grades_df_t = gradebook_df.T\n",
    "\n",
    "# Calculate column means and round them\n",
    "column_means = grades_df_t.mean().round()\n",
    "\n",
    "print(\"Column Means (Rounded):\\n\", column_means)\n",
    "\n",
    "# Fill NaN values with column means\n",
    "grades_df_t = grades_df_t.fillna(column_means)\n",
    "\n",
    "print(\"\\nUpdated DataFrame:\\n\", grades_df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72000866-bd4b-41d2-ac77-85697f0b9fa3",
   "metadata": {},
   "source": [
    "Normalizing Data: Why It Matters\n",
    "\n",
    "When working with datasets, especially in programming and data analytics, normalizing data is a crucial step to ensure consistency, readability, and ease of use. Normalization involves standardizing the data format, which can include renaming columns, formatting values consistently, and preparing the data for analysis. We'll use the mock_data_2 example to demonstrate key normalization techniques, including adding underscores to column names, handling file names with spaces, and converting data to uppercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f0abd-4b49-43aa-823f-d9eaa00a929d",
   "metadata": {},
   "source": [
    "1. Replacing Spaces with Underscores in Column Names\n",
    "\n",
    "   Column names with spaces can lead to coding challenges. For instance, accessing columns with spaces often requires bracket notation (df['Product Name']), whereas standardized column names (df.Product_Name) provide cleaner, more readable code. Replacing spaces with underscores also improves compatibility with various tools and programming languages that may not handle spaces well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3a14d78-94d2-4b80-8a6c-3292534c4831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product_Name', 'Brand_Name', 'Serial_Number', 'Purchase_Date',\n",
      "       'Warranty_Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "mock_data_2 = {\n",
    "    \"Product Name\": [\"LaPtOp\", \"PhOnE\", \"TaBlEt\", \"MoNiToR\", \"KeYbOaRd\"],\n",
    "    \"Brand Name\": [\"DeLl\", \"ApPlE\", \"SaMsUnG\", \"Hp\", \"LoGiTeCh\"],\n",
    "    \"Serial Number\": [\"SN12345\", \"SN67890\", \"SN54321\", \"SN09876\", \"SN11223\"],\n",
    "    \"Purchase Date\": [\"2023-01-15\", \"2022-12-10\", \"2023-05-21\", \"2023-07-30\", \"2023-03-18\"],\n",
    "    \"Warranty Status\": [\"AcTiVe\", \"ExPiReD\", \"AcTiVe\", \"ExPiReD\", \"AcTiVe\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(mock_data_2)\n",
    "\n",
    "# Normalizing column names by replacing spaces with underscores\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a731bd-4fc3-481f-9e45-1a20e36fdbb5",
   "metadata": {},
   "source": [
    "2. The Importance of Avoiding Spaces in File Names\n",
    "\n",
    "   When saving or loading files, spaces in file names can cause issues, especially in terminal commands or when using certain software. For example, to save a DataFrame to a CSV file, using underscores in the file name (mock_data_2.csv) is more practical than dealing with escape characters (mock\\ data\\ 2.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "952e64f1-eca5-49df-8684-14ce20583cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.to_csv of   Product Name Brand Name Serial Number Purchase Date Warranty Status\n",
      "0       LaPtOp       DeLl       SN12345    2023-01-15          AcTiVe\n",
      "1        PhOnE      ApPlE       SN67890    2022-12-10         ExPiReD\n",
      "2       TaBlEt    SaMsUnG       SN54321    2023-05-21          AcTiVe\n",
      "3      MoNiToR         Hp       SN09876    2023-07-30         ExPiReD\n",
      "4     KeYbOaRd   LoGiTeCh       SN11223    2023-03-18          AcTiVe>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "mock_data_2 = {\n",
    "    \"Product Name\": [\"LaPtOp\", \"PhOnE\", \"TaBlEt\", \"MoNiToR\", \"KeYbOaRd\"],\n",
    "    \"Brand Name\": [\"DeLl\", \"ApPlE\", \"SaMsUnG\", \"Hp\", \"LoGiTeCh\"],\n",
    "    \"Serial Number\": [\"SN12345\", \"SN67890\", \"SN54321\", \"SN09876\", \"SN11223\"],\n",
    "    \"Purchase Date\": [\"2023-01-15\", \"2022-12-10\", \"2023-05-21\", \"2023-07-30\", \"2023-03-18\"],\n",
    "    \"Warranty Status\": [\"AcTiVe\", \"ExPiReD\", \"AcTiVe\", \"ExPiReD\", \"AcTiVe\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(mock_data_2)\n",
    "\n",
    "# Normalizing column names by replacing spaces with underscores\n",
    "# df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "df.to_csv('mock_data_2.csv', index=False)  # Clean and simple file name\n",
    "print(df.to_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75249b9b-1c6f-4081-a996-3361aa3b49b2",
   "metadata": {},
   "source": [
    "3. Converting Data to Uppercase\n",
    "\n",
    "   A simple but effective normalization technique is converting all text data to uppercase using .map(str.upper). This approach ensures uniformity, making data comparisons easier and improving overall readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90ed111-bb8d-4549-acf4-b1a73b789d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product Name Brand Name Serial Number Purchase Date Warranty Status\n",
      "0       LAPTOP       DELL       SN12345    2023-01-15          ACTIVE\n",
      "1        PHONE      APPLE       SN67890    2022-12-10         EXPIRED\n",
      "2       TABLET    SAMSUNG       SN54321    2023-05-21          ACTIVE\n",
      "3      MONITOR         HP       SN09876    2023-07-30         EXPIRED\n",
      "4     KEYBOARD   LOGITECH       SN11223    2023-03-18          ACTIVE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "mock_data_2 = {\n",
    "    \"Product Name\": [\"LaPtOp\", \"PhOnE\", \"TaBlEt\", \"MoNiToR\", \"KeYbOaRd\"],\n",
    "    \"Brand Name\": [\"DeLl\", \"ApPlE\", \"SaMsUnG\", \"Hp\", \"LoGiTeCh\"],\n",
    "    \"Serial Number\": [\"SN12345\", \"SN67890\", \"SN54321\", \"SN09876\", \"SN11223\"],\n",
    "    \"Purchase Date\": [\"2023-01-15\", \"2022-12-10\", \"2023-05-21\", \"2023-07-30\", \"2023-03-18\"],\n",
    "    \"Warranty Status\": [\"AcTiVe\", \"ExPiReD\", \"AcTiVe\", \"ExPiReD\", \"AcTiVe\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(mock_data_2)\n",
    "\n",
    "# Normalizing column names by replacing spaces with underscores\n",
    "# df.columns = df.columns.str.replace(' ', '_')\n",
    "# df.to_csv('mock_data_2.csv', index=False)  # Clean and simple file name\n",
    "\n",
    "# Convert all string data to uppercase for consistency\n",
    "df = df.map(str.upper)\n",
    "print(df)\n",
    "#print(df.to_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a8d09-04be-4424-b63d-a8f84c0e705a",
   "metadata": {},
   "source": [
    "Our client, Super-R-US Store, provided us with sales data that requires normalization. It appears that whoever entered the data had some issues with their keyboard, resulting in inconsistent formatting. To standardize the dataset, we will update column names by replacing spaces with underscores to align with our naming conventions. Additionally, we'll convert all raw data to uppercase to match how records are stored in our system, ensuring uniformity and ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38ef836c-84ce-4326-8804-6dd0eab5fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['First_Name', 'Last_Name', 'Email_Address', 'Phone_Number',\n",
      "       'Street_Address'],\n",
      "      dtype='object')\n",
      "  First_Name Last_Name        Email_Address  Phone_Number  Street_Address\n",
      "0      ALICE     SMITH    ALICE@EXAMPLE.COM  123-456-7890     123 MAIN ST\n",
      "1        BOB     JONES      BOB@EXAMPLE.COM  234-567-8901  456 SECOND AVE\n",
      "2    CHARLIE     BROWN  CHARLIE@EXAMPLE.COM  345-678-9012  789 THIRD BLVD\n",
      "3      DAVID    WILSON    DAVID@EXAMPLE.COM  456-789-0123   101 FOURTH RD\n",
      "4        EVA    TAYLOR      EVA@EXAMPLE.COM  567-890-1234    202 FIFTH LN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Customers = {\n",
    "    \"First Name\": [\"aLiCe\", \"bOb\", \"ChArLiE\", \"DaViD\", \"eVa\"],\n",
    "    \"Last Name\": [\"SmItH\", \"JoNeS\", \"BrOwN\", \"WiLsOn\", \"TaYlOr\"],\n",
    "    \"Email Address\": [\"aLiCe@example.com\", \"bOb@example.com\", \"cHaRlIe@example.com\", \"DaViD@example.com\", \"eVa@example.com\"],\n",
    "    \"Phone Number\": [\"123-456-7890\", \"234-567-8901\", \"345-678-9012\", \"456-789-0123\", \"567-890-1234\"],\n",
    "    \"Street Address\": [\"123 MaIn St\", \"456 SeCoNd Ave\", \"789 ThIrD Blvd\", \"101 FoUrTh Rd\", \"202 FiFtH Ln\"]\n",
    "}\n",
    "\n",
    "Customers = pd.DataFrame(Customers)\n",
    "\n",
    "#your code here \n",
    "Customers.columns = Customers.columns.str.replace(' ','_')\n",
    "print(Customers.columns)\n",
    "\n",
    "#your code here\n",
    "Customers = Customers.map(str.upper)\n",
    "print(Customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c69fc09b-4958-4714-bd71-b2f8fe93b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CalYear Employee_Name          Department               jobTitle  \\\n",
      "0     2020           NaN  Parks & Recreation     Park Worker II-CDL   \n",
      "1     2020           NaN  Parks & Recreation  Recreation Instructor   \n",
      "2     2020           NaN  Parks & Recreation        Recreation Aide   \n",
      "3     2020           NaN      Human Services  Staff Helper/Internal   \n",
      "4     2020           NaN  Parks & Recreation        Recreation Aide   \n",
      "\n",
      "   Annual_Rate  Regular_Rate  Overtime_Rate  Incentive_Allowance  Other  \\\n",
      "0      33321.6       1249.56            0.0                  0.0    NaN   \n",
      "1      22880.0        569.25            0.0                  0.0    NaN   \n",
      "2      21840.0        152.25            0.0                  0.0    NaN   \n",
      "3      21008.0        333.30            0.0                  0.0    NaN   \n",
      "4      21840.0        152.25            0.0                  0.0    NaN   \n",
      "\n",
      "   YTD_Total  ObjectId  \n",
      "0    1249.56         1  \n",
      "1     569.25         2  \n",
      "2     152.25         3  \n",
      "3     333.30         4  \n",
      "4     152.25         5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CodeYouOrg/DataOpenClass/refs/heads/main/SalaryData.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae48078-e850-47c4-8cc2-89eb52d4f27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
